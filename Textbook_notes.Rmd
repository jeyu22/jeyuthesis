---
title: "Textbook Notes"
author: '""'
date: "9/19/2021"
output: html_document
---


Longitudinal Textbook 



Chapter 1.

The goal of longitudinal analysis is to observe change over time and analyze the factors that contribute to change. By taking repeated measures of the same person at different times, we can observe this change. Cross sectional analysis and other methods are not able to accomplish this. Since each measure is not independent of one another and correlation exists, specific unique methods must be implemented. Not only can we observe change over time in individuals, but we can look at higher-level grouping, such as change in schools, counties, and organizations. 

To do longitudinal analysis we implement general regression model: a regression model shows exactly how the mean of the response variable changes depending on the covariates. 

Longitudinal analysis can be applied widely to different fields. Most commonly is used when analyzing health data, or measuring the effectiveness of some sort of treatment. 




Chapter 2.

The key component of longitudinal analysis is that there needs to be 2+ observations of the response variable taken at different times for each individual, but they do not need be spaced out evenly. We refer the measure of individual change as a “response trajectory”, with one type of response trajectory being difference scores. LA and the hypotheses constructed can be done in multiple ways; for example, we could look at just post-treatment results between two groups, or compare the rate of decline in symptoms. Since we are taking multiple observations of the same person, we eliminate some within individual variability such as gender/sex/socioeconomic status that could interfere with results. In LA, missing data is a very common feature. One important component of LA is that there is non-zero correlation among repeated measures, which violates regular regression assumptions. We construct correlation and covariance matrices between all the repeated measures for a given individual, and we see that there is unequal variance between measurements over time, but overall all correlations are positive. Repeated measures that were obtained closer to each other have higher correlation. There are three sources of correlation: (1): between-individual, which stems from the fact that repeated measures of one person are more similar than to other individuals. (2): Within individual biological variation: heart rate, cholesterol (3): Measurement error. Measurements that are unreliable will shrink correlation between data points. 

Key takeaway: Correlation is super important! Ignoring correlation leads to overestimating the variation of measure of change. 


Chapter 3.


One of the assumptions of longitudinal analysis is that the responses have a multivariate normal distribution, but it is not required. 

Structure of covariates: if there are p covariates, there exists a p x n matrix that captures all covariates in the analysis for each distinct measurement. There are FIXED covariates (like gender) that do not change and those that change over time. The linear regression model follows a more complex version of y = Bx + e , where B’s are unknown regression coefficients that relate the mean response to the covariate. 

We assume that the errors have a distribution with a mean centered at 0. Conditional distribution of the response variable has a mean centered at XiB, and can be multivariate normally distributed. Univariate normality in separate components DOES NOT equal multivariate normality. Assumptions of multivariate normality are not needed when data are complete. 

We can plot mean response over time, and use smoothing techniques like LOWESS to estimate missing responses. Imagine a window centered at time t. A straight line is fitted inside the window, but observations closer to the center are given more weight. Missing values are predicted by using the fitted line!

The mean is the parameter of interest we want to model but modeling covariances is important as well. There are several ways to model them, one being estimating every possible covariance pair, but this can be very time consuming. We can also use random effects to model the covariance, for example random effects: using a specific single individual random effect variable to account for correlation among repeated measures. AKA a randomly varying intercept.




Chapter 4

Maximum likelihood
We use maximum likelihood as a way to estimate what the values of $\beta$ and $\sigma^2$ are. We choose the value of the estimates that are most likely to occur based on the data observed. In other words, we are maximizing the joint probability of the RV occuring based on the observed data. When we asume that observations are independent of one another, we can use the "ordinary least squares" estimate for $\beta$ (this is only for beta, not variance). However, if we do not assume that repeated measures are independent, and we assume that the covariance is known, we can use the GLS estimator for beta, and it also will be unbiased. If we don't know the covariance the estimator isn't biased, but it is still consistent. 


Missing data: 
There are two types of missing data: those that are missing completely at random (MCAR), and those that are missing at random (MAR). MCAR is when the probability of observations being missing does not depend on the obtained observations nor the underlying population. However, for MAR, the probability of obs being missing depends onthe observed responses, but not the underlying population that should have been sampled. For example, if observations were stratified by their similarity, their probabilities of missingness would be different. The difference between the two types of missing data effects the biasedness and accuracy of the estimators. When there is no assumption of multivariate normal distribution and there is MAR data, then the GLS estimator is no longer valid. However, estimates of beta are valid with MAR when the data is assumed to be from a multivariate normal distribution. 


Statistical Inference:
It is possible to construct confidence intervals using similar methods for proportions and means. We can also use the likelihood ratio tests to determine whether slopes are suitable for LA. The use of standard normal and chi-squared distributions is valid when the covariance is known or the number of observations is large enough. 


Restricted maximum likelihood estimation: in terms of estimating the variance, the ML estimate produced a biased estimate. But if we use REML estimation we will get an unbiased estimator for the variance, because it separates the data used for estimating beta from when it is used to estimate the covariance. In RML we eliminate B from the likelihood function so it is only defined in terms of the covariance. It is estimated to use REML for estimation of covariance and use the GLS estimator for estimating beta. 